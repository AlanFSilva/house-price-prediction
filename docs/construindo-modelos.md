# Prepara√ß√£o dos dados

Durante o pr√©-processamento do dataset, inicialmente foi feita a verifica√ß√£o de valores ausentes, e constatou-se que n√£o havia dados nulos ou vazios, eliminando a necessidade de preenchimento ou remo√ß√£o de linhas. Em seguida, foi aplicado um tratamento de outliers, removendo registros com valores extremos nas vari√°veis **price, bedrooms e bathrooms,** restringindo os valores para at√© 5 milh√µes de d√≥lares no pre√ßo, no m√°ximo 9 quartos e at√© 7 banheiros. Isso ajudou a evitar que pontos fora do padr√£o influenciassem negativamente o desempenho dos modelos.

Na etapa de transforma√ß√£o de dados, foi aplicada a transforma√ß√£o logar√≠tmica √† vari√°vel price, com o objetivo de reduzir a assimetria da distribui√ß√£o e melhorar a performance de algoritmos lineares. A vari√°vel categ√≥rica **zipcode** foi convertida para o formato num√©rico por meio de one-hot encoding, permitindo seu uso por modelos de machine learning.

Foi tamb√©m realizada engenharia de atributos, criando vari√°veis derivadas como:

- **house_age**, calculada com base no ano de constru√ß√£o (2015 - yr_built);
- **was_renovated**, indicando com 1 se a casa foi reformada ou 0 caso contr√°rio;
- **total_sqft**, representando a √°rea total utiliz√°vel da casa, somando sqft_living e sqft_basement.

Al√©m disso, foram extra√≠das caracter√≠sticas polinomiais a partir das coordenadas geogr√°ficas **lat e long**, gerando combina√ß√µes como **lat¬≤, long¬≤ e lat*long,** o que permite capturar rela√ß√µes espaciais n√£o lineares que influenciam o valor dos im√≥veis.

Essas transforma√ß√µes contribu√≠ram para tornar os dados mais adequados ao aprendizado de m√°quina, melhorando a capacidade dos modelos de capturar padr√µes relevantes e realizar previs√µes mais precisas.

```python 
  def transform_zipcode_encoding(df):
      encoding_df = df.copy()
      encoding_df = pd.get_dummies(encoding_df, columns=['zipcode'], prefix='zip')
      return encoding_df

  def transform_df_log_price(df):
      log_df = df.copy()
      log_df['price'] = np.log1p(log_df['price'])
      return log_df

    # Prever e reverter para d√≥lares
    y_pred_log = model.predict(X_test)
    y_pred_dollar = np.expm1(y_pred_log)
    y_true_dollar = np.expm1(y_test)

    # Calcular Previs√µes Reais
    r2 = r2_score(y_true_dollar, y_pred_dollar)
    mse = mean_squared_error(y_true_dollar, y_pred_dollar)
    rmse = np.sqrt(mse)

  from sklearn.preprocessing import PolynomialFeatures

  def transform_df_polynomial(df):
      poly = PolynomialFeatures(degree=2, include_bias=False)
      df_poly = df.copy()
      poly_features = poly.fit_transform(df_poly[['lat', 'long']])
      df_poly[['lat', 'long', 'lat_sq', 'long_sq', 'lat_long']] = poly_features
      return df_poly

```


# Descri√ß√£o dos modelos

## Random Forest Regressor

Para este projeto, implementamos o algoritmo `RandomForestRegressor` como um dos modelos de aprendizado supervisionado. Esse algoritmo pertence √† categoria de ensemble learning e funciona combinando v√°rias √°rvores de decis√£o, de forma que cada √°rvore vote por um valor e a m√©dia das predi√ß√µes seja usada como resultado final.

O Random Forest foi escolhido pelas suas principais vantagens:
- Robustez contra overfitting
- Capacidade de modelar rela√ß√µes n√£o lineares
- Import√¢ncia de vari√°veis interpret√°vel

Diversas vers√µes do modelo foram treinadas e avaliadas com varia√ß√µes no conjunto de dados, incluindo:
- Remo√ß√£o da vari√°vel `zipcode`
- Engenharia de atributos: `house_age`, `was_renovated`, `total_sqft`
- Transforma√ß√µes em `latitude` e `longitude` (polin√¥mios e bins)
- Aplica√ß√£o de `log(price)` para suavizar a distribui√ß√£o de pre√ßos

Essas vers√µes foram avaliadas com base em suas m√©tricas de desempenho (RMSE, MSE, R¬≤, erro percentual) para identificar o modelo mais eficaz.

## Linear Regression 

A regress√£o linear √© um m√©todo estat√≠stico usado para modelar a rela√ß√£o entre uma vari√°vel dependente (alvo) e uma ou mais vari√°veis independentes (preditoras), assumindo que essa rela√ß√£o pode ser aproximada por uma linha reta. Ela estima os coeficientes de uma equa√ß√£o linear que melhor se ajusta aos dados, de forma a minimizar a soma dos erros quadr√°ticos entre os valores previstos e os reais.

A ideia √© modelar uma rela√ß√£o linear entre price e um conjunto de vari√°veis explicativas (features), ajustando uma equa√ß√£o da forma:

y = Œ≤0 + Œ≤1x1 + Œ≤2x2 + ‚ãØ + Œ≤nxn

onde ùë¶ √© a estimativa de price, ùë•1,ùë•2,‚Ä¶,ùë•ùëõ s√£o as features como bedrooms, bathrooms, sqft_living, etc., e os Œ≤ s√£o os coeficientes aprendidos pelo modelo que indicam a influ√™ncia de cada vari√°vel no pre√ßo final.
‚Äã

Durante o treinamento, o modelo ajusta os coeficientes de forma a minimizar a soma dos quadrados dos res√≠duos entre os valores reais de price e os valores previstos ùë¶. Isso resulta em uma fun√ß√£o de predi√ß√£o que pode ser usada para estimar o pre√ßo de casas com base nas caracter√≠sticas fornecidas. Essa abordagem √© especialmente √∫til por sua interpretabilidade e simplicidade matem√°tica.

# Avalia√ß√£o dos modelos criados

Os processos de valida√ß√£o MAE (Erro Absoluto M√©dio), MSE (Erro Quadr√°tico M√©dio), RMSE (Raiz do Erro Quadr√°tico M√©dio) e R¬≤ (Coeficiente de Determina√ß√£o) s√£o m√©tricas fundamentais para avaliar modelos de regress√£o, como Linear Regression e Random Forest em tarefas de previs√£o de valores cont√≠nuos.

## M√©tricas utilizadas

O MAE calcula a m√©dia das diferen√ßas absolutas entre as previs√µes e os valores reais, sendo intuitivo e robusto a outliers. O MSE mede a m√©dia dos quadrados dos erros, penalizando mais erros grandes, mas sua escala √© menos interpret√°vel. O RMSE resolve isso ao extrair a raiz quadrada do MSE, retornando √† unidade original dos dados. O R¬≤ indica a propor√ß√£o da vari√¢ncia dos dados que o modelo consegue explicar, variando de 0 (pior) a 1 (melhor).

Ambos os modelos (Linear Regression e Random Forest) podem ser avaliados com essas m√©tricas, mas o Random Forest, por ser baseado em √°rvores e capturar rela√ß√µes n√£o lineares, tende a ter menor MAE/MSE/RMSE e maior R¬≤ em dados complexos, embora com risco de overfitting. Essas m√©tricas permitem comparar a precis√£o das previs√µes e a capacidade de generaliza√ß√£o dos modelos, independentemente do algoritmo utilizado.

## Discuss√£o dos resultados obtidos

O modelo `RandomForestRegressor` foi testado com cinco varia√ß√µes principais dos dados. A compara√ß√£o envolveu:

- Conjunto base sem `zipcode`
- Base com atributos derivados (ex: `house_age`)
- Base com polin√¥mios de `lat` e `long`
- Base com `lat/long` convertidos em bins (regi√µes discretas)
- Transforma√ß√£o logar√≠tmica da vari√°vel `price`

A vers√£o com `log(price)` obteve o **menor erro absoluto (RMSE ‚âà 0.0015)** e o **menor erro percentual m√©dio (18.37%)**, sendo a mais eficaz para melhorar a precis√£o. J√° a vers√£o sem `zipcode`, com os dados brutos, alcan√ßou o **maior R¬≤ (0.8885)**, explicando melhor a vari√¢ncia do pre√ßo.

Isso demonstra que o Random Forest √© robusto e consistente, mesmo com diferentes representa√ß√µes dos dados. O uso de engenharia de atributos e transforma√ß√µes contribuiu positivamente para o desempenho final.

| Vers√£o                        | RMSE     | MSE          | R¬≤     | Erro percentual |
|-------------------------------|----------|--------------|--------|-----------------|
| Sem zipcode                   | 0.003458 | 0.00001196   | 0.8885 | 0.27%           |
| Vari√°veis novas + sem zipcode | 0.003497 | 0.00001223   | 0.8860 | 0.27%           |
| Polin√¥mios em lat/long        | 0.003498 | 0.00001224   | 0.8859 | 0.27%           |
| Com bins lat/long             | 0.003484 | 0.00001214   | 0.8868 | 0.27%           |
| Log(price)                    | 0.001524 | 0.00000232   | 0.8860 | 0.18%           |


O modelo de `Linear Regression` foi testado com diversas varia√ß√µes principais dos dados. A compara√ß√£o envolveu:

- Conjunto base sem nenhuma altera√ß√£o
- Conjunto base sem `zipcode`
- Conjunto base sem `zipcode, Lat e Long`
- Base com atributos derivados (ex: `house_age`)
- Base com polin√¥mios de `lat` e `long`
- Base com `lat/long` convertidos em bins (regi√µes discretas)
- Transforma√ß√£o logar√≠tmica da vari√°vel `price`
- Transforma√ß√£o one-hot encoding do `zipcode`
- Combina√ß√£o do one-hot encoding do `zipcode` com polin√¥mios de `lat` e `long`
- Combina√ß√£o do one-hot encoding do `zipcode` com polin√¥mios de `lat` e `long` e atributos derivados
-  Combina√ß√£o do one-hot encoding do `zipcode` com polin√¥mios de `lat` e `long` e Transforma√ß√£o logar√≠tmica da vari√°vel `price`
-  Combina√ß√£o do one-hot encoding do `zipcode` com polin√¥mios de `lat` e `long` e Remo√ß√£o leve de alguns Outliers
-  Combina√ß√£o do one-hot encoding do `zipcode` com polin√¥mios de `lat` e `long` e Transforma√ß√£o logar√≠tmica da vari√°vel `price` e Remo√ß√£o leve de alguns Outliers

O modelo original apresentou um RMSE de aproximadamente 212 mil e um R¬≤ de 0.7005, servindo como base comparativa. A exclus√£o de atributos geogr√°ficos como zipcode, lat e long levou a uma piora consider√°vel no desempenho, indicando que a localiza√ß√£o √© um fator crucial para a previs√£o de pre√ßos. 

| Modelo                                     | RMSE         | R¬≤     |
|--------------------------------------------|-------------:|-------:|
| Modelo Original                            | 212,008.67   | 0.7005 |
| Modelo Sem Zipcode                         | 213,724.81   | 0.6957 |
| Modelo Sem Zipcode, Lat e Long             | 228,210.44   | 0.6530 |
| Modelo com modifica√ß√£o de colunas          | 216,377.03   | 0.6881 |
| Modelo com transforma√ß√£o polinomial        | 204,099.31   | 0.7225 |
| Modelo com Spatial Binning                 | 211,679.92   | 0.7015 |
| Modelo com logaritmo do Price              | 273,734.13   | 0.5008 |
| Modelo com one-hot encoding do Zipcode     | 169,539.73   | 0.8085 |
| Modelo com encoding e polinomial           | 169,372.19   | 0.8089 |
| Modelo com enc, poly e mod colunas         | 177,853.15   | 0.7892 |
| Modelo com enc, poly e log price           | 220,918.85   | 0.6748 |
| Modelo com enc, poly e outliers            | 151,283.12   | 0.8226 |
| Modelo com enc, poly, log price e outliers | 136,441.85   | 0.8557 |

 A combina√ß√£o de encoding + polin√¥mios refinou ainda mais os resultados, tornando-se o melhor modelo. Por outro lado, a transforma√ß√£o logar√≠tmica do pre√ßo prejudicou drasticamente o modelo, indicando incompatibilidade com a distribui√ß√£o dos dados ou a m√©trica utilizada.


# Pipeline de pesquisa e an√°lise de dados

Para a modelagem com Random Forest e LinearRegression, seguimos um pipeline bem definido e replic√°vel:

1. **Pr√©-processamento**: remo√ß√£o de colunas irrelevantes e outliers, tratamento de duplicatas, cria√ß√£o de atributos derivados;
2. **Divis√£o dos dados**: 80% para treino, 20% para teste;
3. **Treinamento**: uso da fun√ß√£o `train_random_forest()` com modularidade para testes variados;
4. **Avalia√ß√£o**: fun√ß√£o `evaluate_random_forest_model()` com retorno das m√©tricas principais;
5. **Compara√ß√£o estruturada**: tabela `df_results` para comparar todas as vers√µes testadas;
6. **Escolha final**: melhor vers√£o identificada com base em RMSE e R¬≤, levando em conta o objetivo da predi√ß√£o.

Esse pipeline foi reutiliz√°vel e permitiu analisar com clareza o impacto de cada modifica√ß√£o nos dados.

```python 
# Fun√ß√£o de treino
def train_random_forest(df, test_size=0.2, random_state=42, drop_columns=[]):
    drop_columns.extend(['id', 'date', 'price'])
    X = df.drop(drop_columns, axis=1)
    y = df['price']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    rf_model = RandomForestRegressor(n_estimators=100, random_state=random_state)
    rf_model.fit(X_train, y_train)

    return {
        'model': rf_model,
        'X_test': X_test,
        'y_test': y_test,
        'X_train': X_train,
        'y_train': y_train,
        'feature_names': X.columns.tolist()
    }

# Fun√ß√£o de avalia√ß√£o
def evaluate_random_forest_model(results):
    model = results['model']
    X_test = results['X_test']
    y_test = results['y_test']
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    erro_percentual = (rmse / y_test.mean()) * 100

    # Import√¢ncia das features
    importances = pd.DataFrame({
        'Feature': results['feature_names'],
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)

    # Impress√£o das m√©tricas
    print("Random Forest Performance:")
    print(f"MSE: {mse:,.2f}")
    print(f"RMSE: {rmse:,.2f}")
    print(f"R-squared: {r2:.4f}")
    print(f"Erro percentual m√©dio: {erro_percentual:.2f}%")
    print("\nTop 5 Important Features:")
    print(importances)

   # Gr√°fico: valores reais vs previstos
    print("\n")
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title('Actual vs Predicted Values')
    plt.grid(True)
    plt.show()

    # Gr√°fico de res√≠duos
    print("\n")
    residuals = y_test - y_pred
    plt.figure(figsize=(10, 6))
    plt.scatter(y_pred, residuals, alpha=0.5)
    plt.axhline(y=0, color='r', linestyle='-')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.title('Residual Analysis')
    plt.grid(True)
    plt.show()
    print("\n")

    return {
        'RMSE': rmse,
        'MSE': mse,
        'R2': r2,
        'Erro percentual': erro_percentual
    }
```

# An√°lise Comparativa de Modelos de Regress√£o para Previs√£o do Dataset 

Realizamos testes com diversos modelos de regress√£o aplicados ao nosso dataset, removendo colunas irrelevantes (como id, date, price, entre outras) e avaliando o desempenho com base em m√©tricas padronizadas. Os resultados foram organizados de forma a facilitar a interpreta√ß√£o comparativa.

Foram utilizados cinco modelos: **Gradient Boosting, XGBoost, LightGBM, Random Forest e Regress√£o Linear**. Os quatro primeiros s√£o algoritmos baseados em √°rvores de decis√£o, com varia√ß√µes em efici√™ncia, paraleliza√ß√£o e estrat√©gias de crescimento. J√° a **Regress√£o Linear** representa uma abordagem mais simples e interpret√°vel, baseada na suposi√ß√£o de rela√ß√£o linear entre as vari√°veis.

A avalia√ß√£o foi feita por meio das m√©tricas MAE, MSE, RMSE, R¬≤ e erro percentual (RMSE relativo √† m√©dia dos valores reais). A tabela a seguir resume os resultados:

| Modelo              | MAE        | MSE              | RMSE       | R¬≤     | Erro Percentual |
|---------------------|------------|------------------|------------|--------|-----------------|
| **Gradient Boosting**   | 74.114,61  | 16.167.312.530,00 | 127.150,75 | 0,8747 | 23,48%          |
| **XGBoost**             | 65.467,44  | 12.936.883.614,68 | 113.740,42 | 0,8997 | 21,01%          |
| **LightGBM**            | 64.842,25  | 12.444.102.256,10 | 111.553,14 | 0,9035 | 20,60%          |
| **Random Forest**       | 68.699,67  | 15.160.600.854,06 | 123.128,39 | 0,8825 | 22,74%          |
| **Linear Regression**   | 74.683,45  | 18.616.377.895,61 | 136.441,85 | 0,8557 | 25,20%          |

O **LightGBM** apresentou o melhor desempenho geral, com menor erro e maior coeficiente de determina√ß√£o, al√©m de ser mais eficiente em termos computacionais. O XGBoost se mostrou uma alternativa s√≥lida, especialmente √∫til quando interpretabilidade e regulariza√ß√£o s√£o relevantes. Random Forest e Gradient Boosting tiveram desempenho intermedi√°rio, enquanto a Regress√£o Linear teve os piores resultados, sendo adequada apenas em cen√°rios onde a simplicidade do modelo √© priorit√°ria.

### Limita√ß√µes identificadas:

- Os erros percentuais, entre **20% e 25%**, ainda s√£o elevados para aplica√ß√µes sens√≠veis, como previs√µes financeiras.
- Os hiperpar√¢metros n√£o foram otimizados (utilizou-se **n_estimators=100** como padr√£o).
- A aus√™ncia de normaliza√ß√£o pode ter prejudicado o desempenho da Regress√£o Linear.

### Pr√≥ximos passos recomendados:

- Realizar tuning de hiperpar√¢metros (ex.: profundidade das √°rvores, learning rate).
- Investigar a presen√ßa de outliers e incluir novas vari√°veis relevantes.
- Testar pr√©-processamento adicional, como normaliza√ß√£o e transforma√ß√£o de features.
- Explorar combina√ß√µes de modelos (ensembles h√≠bridos) para maior robustez.

# V√≠deo de apresenta√ß√£o da Etapa 03

[video de apresenta√ß√£o Etapa 3](videos/ProjetoHousePricing-Etapa3.mp4)
